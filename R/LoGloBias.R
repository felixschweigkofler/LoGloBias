#' Create non-representative example data for a performance-focused task
#'
#' Create example trial-level local-global data from experiment in which a participant's performance is evaluated. The data does not represent any real patterns and merely severs to demonstrated the required structure.
#' @param mean.RT,sd.RT Overall mean and standard deviation values being passed to rnorm() to create example reaction times. Any negative values generated by rnorm() will be made positive. Default to 400 and 150, respectively.
#' @param mean.accuracy Overall mean accuracy used to create example accuracies. Defaults to 0.9.
#' @param level A vector of level identifiers, describing the level of EACH trial in an experiment. Is being used to determine (together with the length of 'congruence') the number of trials for each participant, for each session. Defaults to c(rep('loc',5), rep('glo',5)).
#' @param congruence A vector of level identifiers, describing which KINDS of congruence exists. Is being used to determine (together with the length of 'level') the number of trials. Defaults to c('con','inc').
#' @param id,session Vectors of participant and session identifiers. Default to 1:8 and 1:2 respectively.
#' @param format Defines if a true long format dataframe ('long') or a long-wide hybrid ('wide') is returned. Defaults to 'wide'.
#' @keywords example, data
#' @export
#' @examples
#' example.performance.data()
example.performance.data = function(mean.RT = 400, sd.RT = 150, mean.accuracy = 0.9, level = c(rep('loc',5), rep('glo',5)), congruence = c('con','inc'), id = 1:10, session = 1:2, format = 'wide', seed = NULL){
  set.seed(seed = seed)
  # Create a long dataframe of example trial data for 10 participants in a 2-session experiment with 5 local and 5 global trials, half of them congruent and half incongruent
  tr = expand.grid(list(measure = c('RT','ACC'), congruence = congruence, level = level, id = id, session = session))
  tr$trial = rep(1:(length(level)*length(congruence)), each = 2)
  tr$value = NA
  tr$value[seq(2,nrow(tr),2)] = sample(c(rep(0,round(1-mean.accuracy, 3) * 1000), rep(1,round(mean.accuracy, 3) * 1000)), nrow(tr)/2, replace = T)
  tr$value[seq(1,nrow(tr),2)] = abs(rnorm(nrow(tr)/2, mean = mean.RT, sd = sd.RT))
  tr$congruence = rep(as.vector(apply(matrix(tr[tr$measure == 'RT','congruence'], nrow = length(level)), 2, sample)), each = 2)
  tr = tr[,c('session','id','trial','level','congruence','measure','value')]
  if(format == 'wide') return(tidyr::pivot_wider(tr, names_from = 'measure')) else return(tr)
}


#' Create non-representative example data for a preference-focused task
#'
#' Create example trial-level local-global data from experiment in which a participant's preference is evaluated. The data does not represent any real patterns and merely severs to demonstrated the required structure.
#' @param mean.RT,sd.RT Overall mean and standard deviation values being passed to rnorm() to create example reaction times. Any negative values generated by rnorm() will be made positive. Default to 400 and 150, respectively.
#' @param mean.preference Overall mean preference used to create example preferences. Defaults to 0.5, which means equal chance of having a local or global preference.
#' @param congruence A vector of level identifiers, describing which KINDS of congruence exists. Is being used to determine (together with the length of 'level') the number of trials. Defaults to c('con','inc').
#' @param id,session Vectors of participant and session identifiers. Default to 1:8 and 1:2 respectively.
#' @param format Defines if a true long format dataframe ('long') or a long-wide hybrid ('wide') is returned. Defaults to 'wide'.
#' @keywords example, data
#' @export
#' @examples
#' example.preference.data()
example.preference.data = function(mean.RT = 400, sd.RT = 150, mean.preference = 0, congruence = c(rep('con',5), rep('inc',5)), id = 1:8, session = 1:2, format = 'wide', seed = NULL){
  set.seed(seed = seed)
  # Create a long dataframe of example trial data for 10 participants in a 2-session experiment with 5 local and 5 global trials, half of them congruent and half incongruent
  tr = expand.grid(list(measure = c('RT','PREF'), congruence = congruence, id = id, session = session))
  tr$trial = rep(1:length(congruence), each = 2)
  tr$value = NA
  tr$value[seq(2,nrow(tr),2)] = sample(c(rep(-1,1000-round(mean.preference*1000)), rep(1,1000-round(-mean.preference*1000))), nrow(tr)/2, replace = T)
  tr$value[seq(1,nrow(tr),2)] = abs(rnorm(nrow(tr)/2, mean = mean.RT, sd = sd.RT))
  tr$congruence = rep(as.vector(apply(matrix(tr[tr$measure == 'RT','congruence'], nrow = length(congruence)), 2, sample)), each = 2)
  tr = tr[,c('session','id','trial','congruence','measure','value')]
  if(format == 'wide') return(tidyr::pivot_wider(tr, names_from = 'measure')) else return(tr)
}


#' Return the default metric instructions
#'
#' A function that just returns hard-coded calculation instructions for the default metrics.
#' @keywords score
#' @export
#' @examples default.metrics()
default.metrics = function(){return(data.frame('OPS' = c('loc','glo','diff'),
                                               'OIS' = c('inc','con','diff'),
                                               'OYS' = c('inc','ctr','diff'),
                                               'OJS' = c('con','ctr','diff'),
                                               'LIS' = c('glo.inc','glo.con','diff'),
                                               'LYS' = c('glo.inc','glo.ctr','diff'),
                                               'LJS' = c('glo.con','glo.ctr','diff'),
                                               'GIS' = c('loc.inc','loc.con','diff'),
                                               'GYS' = c('loc.inc','loc.ctr','diff'),
                                               'GJS' = c('loc.con','loc.ctr','diff'),
                                               'IPS' = c('loc.inc','glo.inc','diff'),
                                               'CPS' = c('loc.con','glo.con','diff'),
                                               'NPS' = c('loc.ctr','glo.ctr','diff'),
                                               'BIS' = c('IPS','CPS','diff'),
                                               'BYS' = c('IPS','NPS','diff'),
                                               'BJS' = c('CPS','NPS','diff'),
                                               'SIS' = c('GIS','LIS','min'),
                                               'SYS' = c('GYS','LYS','min'),
                                               'SJS' = c('GJS','LJS','min'),
                                               row.names = c('R1','R2','method')))}


#' Return the default metric instructions
#'
#' A function that just returns hard-coded calculation instructions for the default metrics.
#' @keywords score
#' @export
#' @examples preference.metrics()
preference.metrics = function(){return(data.frame('OPS' = c('all',NA,NA),
                                                  'IPS' = c('inc',NA,NA),
                                                  'CPS' = c('con',NA,NA),
                                                  'NPS' = c('ctr',NA,NA),
                                                  'BIS' = c('IPS','CPS','diff'),
                                                  'BYS' = c('IPS','NPS','diff'),
                                                  'BJS' = c('CPS','NPS','diff'),
                                                  row.names = c('R1','R2','method')))}


#' Summarise trials of a local-global preference bias experiment
#'
#' Group trials of a local-global bias experiment in which a participant's preference instead of accuracy is measured. Group trials in a long format dataframe and apply defineable summary statistic functions to the measures. A trial's level is defined by the choice the participant made.
#' @param ldf Wide-long hybrid dataframe with the trial data. The columns defined by 'measure.cols' contain the values and the other columns are either irrelevant or are used as identifier-columns to index these values.
#' @param measure.cols Names of the columns containing the measures. Default to c('ACC','RT') for accuracy and reaction time. Values must be numeric. Accuracy must be coded as 1 or 0. The error rate is automatically calculated from accuracy.
#' @param accuracy,error_rate The names of the columns that contain accuracy and error rate. If accuracy exists, but not error rate, the error rate is automatically calculated and gets the named defined by 'error_rate'. Default to ACC and ER.
#' @param group.by,group.by0 Identifier-columns that are used create trial-groupings, within which statistics are calculated. The column names defined by group.by are used to create a power set (all possible combinations, including NULL), while the column names specified by group.by0 are added to each element of the power set. The resulting sets with combinations of column names are used iteratively when grouping the data (see examples). Default to NULL.
#' @param correct.trials.only Removes all values that are not accuracy or error rate from trials with an accuracy of 1. Defaults to TRUE.
#' @param calculate A 2*x dataframe with instructions how to calculate summary statistics within the groupings. Column names specify the name for the summary statistic, the first row specifies the measure to be summarised, and the second row the function to be used. The function must accept a vector and output a scalar. Defaults to data.frame(mean_ACC = c('ACC','mean'), ER = c('ER','mean'), mean_RT = c('RT','mean'), median_RT = c('RT','median')).
#' @param make.trial_type Columns to be used to create a singular trial_type column. Can only specify 1 or 2 columns to be used (e.g. level and congruence). Defaults to NULL.
#' @importFrom dplyr '%>%'
#' @keywords summary
#' @export
#' @examples
#' # Group by the power set of session, id, level, and congruence. Use default 'calculate'-instructions.
#' ldf = summarise.trials(wdf = example.performance.data(), group.by = c('session','id','level','congruence'))
#' # Group by the power set of level and congruence and the normal set of session and id. Now, only summaries that differentiate by session and id are calculated (e.g. no overall summary over the entire data)
#' ldf = summarise.trials(wdf = example.performance.data(), group.by = c('level','congruence'), group.by0 = c('session','id'))
#' # Calculate the sd of RT for the entire dataset and no other summary. Also, use all RTs, not only the RTs from correct trials.
#' ldf = summarise.trials(wdf = example.performance.data(), calculate = data.frame(sd_of_all_RT = c('RT','sd')), correct.trials.only = F)
summarise.trials = function(wdf, group.by = NULL, group.by0 = NULL, fuse.by = NULL, correct.trials.only = T, calculate = data.frame(mean_ACC = c('ACC','mean'), mean_ER = c('ER','mean'), mean_RT = c('RT','mean'), median_RT = c('RT','median')), measure.cols = c('ACC','RT'), accuracy = 'ACC', error_rate = 'ER', make.trial_type = NULL){

  for(i in measure.cols) if(!i %in% colnames(wdf)) stop("'measure.cols' requires [",i,"] but it does not exist in the column names of 'wdf'")
  if(!is.null(group.by)) if(any(!group.by %in% colnames(wdf))) stop("[",paste(group.by[!group.by %in% colnames(wdf)], collapse = ', '),"] is required by 'group.by' but not present in the colnames of 'wdf'")
  if(!is.null(group.by0)) if(any(!group.by0 %in% colnames(wdf))) stop("[",paste(group.by0[!group.by0 %in% colnames(wdf)], collapse = ', '),"] is required by 'group.by0' but not present in the colnames of 'wdf'")
  if(any(group.by %in% group.by0)) stop("'group.by' and 'group.by0' cannot contain the same colum names")

  rownames(calculate) = c('measure','method')
  if(any(!calculate['measure',] %in% c(measure.cols, error_rate))) stop("'calculate' requires ",paste(calculate['measure',!calculate['measure',] %in% c(measure.cols,error_rate)], collapse = ',')," which does not exist in the colnames of 'wdf'")

  if(any(!unlist(lapply(wdf[,measure.cols],is.numeric)))) stop("The measure columns must be numeric")

  if(accuracy %in% colnames(wdf)) if(any(!wdf[[accuracy]] %in% c(1,0,NA))) stop("The accuracy can only be coded as 0 (incorrect) or 1 (correct). Missing values must be NA.")
  if(!is.null(correct.trials.only)) if(!accuracy %in% colnames(wdf)) stop("To remove incorrect trials, 'accuracy' must index the column with the accuracy-data.")

  for(i in c('trial_type','sum.of.ACC','sum.of.RT')) if(i %in% colnames(wdf)) stop("'wdf' cannot contain a column called [",i,"], as it is used internally.")
  if(any(!make.trial_type %in% colnames(wdf))) stop("'make.trial_type' can only define column names that exist in wdf")
  if(length(make.trial_type) > 2) stop("'make.trial_type' can not define more than two columns")

  # If accuracy is present, calculate the error from the accuracy
  if(accuracy %in% colnames(wdf)) wdf[[error_rate]] = 1 - wdf[[accuracy]]

  # If required, trim the RT of wrong trials. Create wdf2 to use for the calculation of RCS
  wdf2 = wdf
  if(correct.trials.only) wdf[!wdf[[accuracy]] %in% 1, measure.cols[!measure.cols %in% c(accuracy,error_rate)]] = NA

  # Create the power set of group.by (NULL if group.by is NULL)
  a = list(NULL)
  if(!is.null(group.by))
    for(j in 1:length(group.by)) a = c(a, combn(group.by, m=j, simplify=F))
  # Add group.by0 to each element of the power set
  a = lapply(a, function(vec) c(vec,group.by0))
  message('Provided grouping instructions'); print(a)

  A = data.frame(matrix(nrow = 1, ncol = length(group.by)+length(group.by0)+2))
  colnames(A) = c(group.by0,group.by,'measure','value')
  # For each summary method and each combination of grouping columns
  for (i in 1:ncol(calculate))
    for (j in 1:length(a))
      suppressMessages({
        # Group the value-col by all cols defined in group.by and then call the method specified in calculate on the measure specified in calculate
        A0 = wdf %>% dplyr::group_by(dplyr::across(dplyr::all_of(a[[j]]))) %>% dplyr::summarise(value = do.call(match.fun(calculate['method',i]), list(!!dplyr::sym(calculate['measure',i]), na.rm = T)))
        # Add a column with name of this measure and rowbind it to the main df
        A0$measure = colnames(calculate)[i]
        A = dplyr::bind_rows(A, A0)})
  # Remove the first empty row
  A = A[-1,]

  # Create the trial_type and reorder the colums if required
  if(!is.null(make.trial_type)) {
    if(length(make.trial_type) == 1) A$trial_type = A[[make.trial_type]] else A$trial_type = ifelse(is.na(A$level) & is.na(A$congruence), 'all', ifelse(is.na(A$level), as.character(A$congruence),ifelse(is.na(A$congruence), as.character(A$level),paste(A$level, A$congruence, sep = "."))))
    A = A[,c(group.by0,group.by,'trial_type','measure','value')]} else A = A[,c(group.by0,group.by,'measure','value')]

  return(as.data.frame(A))
}


#' Summarise trials of a local-global preference bias experiment
#'
#' Group trials of a local-global bias experiment in which a participant's preference instead of accuracy is measured. Group trials in a long format dataframe and apply defineable summary statistic functions to the measures. A trial's level is defined by the choice the participant made.
#' @param ldf Wide-long hybrid dataframe with the trial data. The columns defined by 'measure.cols' contain the values and the other columns are either irrelevant or are used as identifier-columns to index these values.
#' @param measure.cols Names of the columns containing the measures. Default to c('PREF','RT') for accuracy and reaction time. Values must be numeric. Accuracy must be coded as 1 or 0. The error rate is automatically calculated from accuracy.
#' @param level.col Name of the to-be-created column that will contain the chosen level (preference) in each trial. If the trials should be grouped by level (group.by/group.by0) for calculation of RTs, this name must be used for the level-column. Is ignored if it does not exist in group.by/group.by0. Defaults to 'level'.
#' @param preference.col Name of the column holding the preference-measure. This name must be used as measure-name in the 'calculate' instructions. Defaults to PREF.
#' @param group.by,group.by0 Identifier-columns that are used create trial-groupings, within which statistics are calculated. The column names defined by group.by are used to create a power set (all possible combinations, including NULL), while the column names specified by group.by0 are added to each element of the power set. The resulting sets with combinations of column names are used iteratively when grouping the data (see examples). Default to NULL.
#' @param calculate A 2*x dataframe with instructions how to calculate summary statistics within the groupings. Column names specify the name for the summary statistic, the first row specifies the measure to be summarised, and the second row the function to be used. The function must accept a vector and output a scalar. Defaults to data.frame(mean_ACC = c('ACC','mean'), ER = c('ER','mean'), mean_RT = c('RT','mean'), median_RT = c('RT','median')).
#' @param make.trial_type Columns to be used to create a singular trial_type column. Can only specify 1 or 2 columns to be used (e.g. level and congruence). Defaults to NULL.
#' @importFrom dplyr '%>%'
#' @keywords summary
#' @export
#' @examples
#' # Group by the power set of session, id, level, and congruence. Use default 'calculate'-instructions.
#' ldf = summarise.trials.PREF(wdf = example.preference.data(), group.by = c('session','id','level','congruence'))
#' # Group by the power set of level and congruence and the normal set of session and id. Now, only summaries that differentiate by session and id are calculated (e.g. no overall summary over the entire data)
#' ldf = summarise.trials.PREF(wdf = example.preference.data(), group.by = c('level','congruence'), group.by0 = c('session','id'))
#' debug(summarise.trials.PREF)
#' summarise.trials.PREF(wdf = example.preference.data(seed = 2),group.by0 = c('session','id','level','congruence'), make.trial_type = c('level','congruence'))
summarise.trials.PREF = function(wdf, group.by = NULL, group.by0 = NULL, calculate = data.frame(mean_PREF = c('PREF','mean'), sum_PREF = c('PREF','sum'), mean_RT = c('RT','mean'), median_RT = c('RT','median')), measure.cols = c('PREF','RT'), level.col = 'level', preference.col = 'PREF', make.trial_type = NULL){

  #TODO: Offer alternative coding for PREF, namely as 0 1 instad of -1 1

  for(i in measure.cols) if(!i %in% colnames(wdf)) stop("'measure.cols' requires [",i,"] but it does not exist in the column names of 'wdf'")
  if(!is.null(group.by)) if(any(!group.by %in% c(colnames(wdf),level.col))) stop("[",paste(group.by[!group.by %in% colnames(wdf)], collapse = ', '),"] is required by 'group.by' but not present in the colnames of 'wdf'")
  if(!is.null(group.by0)) if(any(!group.by0 %in% c(colnames(wdf),level.col))) stop("[",paste(group.by0[!group.by0 %in% colnames(wdf)], collapse = ', '),"] is required by 'group.by0' but not present in the colnames of 'wdf'")
  if(any(group.by %in% group.by0)) stop("'group.by' and 'group.by0' cannot contain the same colum names")

  rownames(calculate) = c('measure','method')
  if(any(!calculate['measure',] %in% measure.cols)) stop("'calculate' requires ",paste(calculate['measure',!calculate['measure',] %in% measure.cols], collapse = ',')," which does not exist in the colnames of 'wdf'")
  if(!preference.col %in% measure.cols) stop("[",preference.col,"] is required by 'preference.col' but does not exist in 'measure.cols'")

  if(any(!unlist(lapply(wdf[,measure.cols],is.numeric)))) stop("The measure columns must be numeric")

  for(i in c('trial_type','sum.of.ACC','sum.of.RT')) if(i %in% colnames(wdf)) stop("'wdf' cannot contain a column called [",i,"], as it is used internally.")
  if(any(!make.trial_type %in% c(colnames(wdf),level.col))) stop("'make.trial_type' can only define column names that exist in 'wdf'")
  if(any(!make.trial_type %in% c(group.by,group.by0))) stop("'make.trial_type' can only define column names that exist in 'group.by' or 'group.by0'")
  if(length(make.trial_type) > 2) stop("'make.trial_type' can not define more than two columns")

  # Remove trials with NA in the preference column
  wdf = wdf[!is.na(wdf[[preference.col]]),]

  # Remove the level from group.by and group.by0
  group.by_PREF  = group.by[ !group.by  %in% level.col]
  group.by0_PREF = group.by0[!group.by0 %in% level.col]
  # Create the power set of group.by (NULL if group.by is NULL)
  a = list(NULL)
  if(!is.null(group.by_PREF))
    for(j in 1:length(group.by_PREF)) a = c(a, combn(group.by_PREF, m=j, simplify=F))
  # Add group.by0 to each element of the power set
  a = lapply(a, function(vec) c(vec,group.by0_PREF))
  message('Provided grouping instructions for PREF'); print(a)

  # Create the final dataframe A, with columns for all grouping variables plus measure and value cols
  A = data.frame(matrix(nrow = 1, ncol = length(group.by)+length(group.by0)+2))
  colnames(A) = c(group.by0,group.by,'measure','value')
  for (i in which(calculate['measure',] %in% preference.col))
    for(j in 1:length(a)) suppressMessages({
      # Group the value-col by all cols defined in group.by and then call the method specified in calculate on the measure specified in calculate
      A0 = wdf %>% dplyr::group_by(dplyr::across(dplyr::all_of(a[[j]]))) %>% dplyr::summarise(value = do.call(match.fun(calculate['method',i]), list(!!dplyr::sym(calculate['measure',i]), na.rm = T)))
      # Add a column with name of this measure and rowbind it to the main df
      A0$measure = colnames(calculate)[i]
      A = dplyr::bind_rows(A, A0)})
  # Remove the first empty row
  A = A[-1,]

  # Recreate the standard level-column from the preference column
  if(level.col %in% c(group.by,group.by0)) {
    wdf[[level.col]] = ifelse(wdf[[preference.col]] == 1, 'glo', 'loc')
    A[[level.col]] = NA}

  # Create the power set of group.by (NULL if group.by is NULL)
  a = list(NULL)
  if(!is.null(group.by))
    for(j in 1:length(group.by)) a = c(a, combn(group.by, m=j, simplify=F))
  # Add group.by0 to each element of the power set
  a = lapply(a, function(vec) c(vec,group.by0))
  message('Provided grouping instructions for non-PREF'); print(a)

  # For each summary method and each combination of grouping columns
  for (i in which(!calculate['measure',] %in% preference.col))
    for (j in 1:length(a))
      suppressMessages({
        # Group the value-col by all cols defined in group.by and then call the method specified in calculate on the measure specified in calculate
        A0 = wdf %>% dplyr::group_by(dplyr::across(dplyr::all_of(a[[j]]))) %>% dplyr::summarise(value = do.call(match.fun(calculate['method',i]), list(!!dplyr::sym(calculate['measure',i]), na.rm = T)), .groups = 'keep')
        # It can happen that a level does not exist for a participant or participant*congruence because the participant never preferred that level
        # To prevent empty rows, create a df containing all hypothetically possible combinations of groupings and left_join so that the missing values become NA
        A1 = expand.grid(lapply(A0[,a[[j]]],unique))
        A0 = dplyr::left_join(A1,A0)
        # Add a column with name of this measure and rowbind it to the main df
        A0$measure = colnames(calculate)[i]
        A = dplyr::bind_rows(A, A0)})

  # Create the trial_type and reorder the colums if required
  if(!is.null(make.trial_type)) {
    if(length(make.trial_type) == 1) A$trial_type = A[[make.trial_type]] else A$trial_type = ifelse(is.na(A$level) & is.na(A$congruence), 'all', ifelse(is.na(A$level), as.character(A$congruence),ifelse(is.na(A$congruence), as.character(A$level),paste(A$level, A$congruence, sep = "."))))
    A = A[,c(group.by0,group.by,'trial_type','measure','value')]} else A = A[,c(group.by0,group.by,'measure','value')]

  return(as.data.frame(A))
}




#' A function to summarise trials of a local-global bias experiment.
#'
#' A function to calculate bias metrics from summary values in a standardised long dataframe. The preference-measure is treated differently from all other measures. Interpret the meaning of metrics carefully, especially what a certain combination of metric and measure mean. Generally, when a large input measure signifies bad performance (e.g. long RT), a resulting positive score indicates a global bias (e.g. in CPS) or a bias for congruent figures (e.g. in LIS), respectively.
#' @param ldf Long format dataframe with one column named 'value' containing the values, one identifier-column named 'measure' describing the summary measure of the value (from summarise.trials()), and one identifer-column named 'type' which merges the information from level and congruence (from summarise.trials()).
#' @param identifier.cols Columns that uniquely index all values with their identifiers. No default.
#' @param metrics A 2*x dataframe with instructions how to calculate metrics as difference or minimum between two summary values. Each column contains instructions for one metric. The column name is the name of the metric to be calculated, the first and second row (R1, R2) specify either a summary type from the type-column in 'ldf' or a metric that was previously calculated, the third row specifies the method to be used to calculate the metric from the entries in row 1 and 2. Currently, only 'diff'  (score = R1 - R2) and 'min' (score = min(R1, R2, na.rm = F)) are implemented. When the function does not find the inputs required by a metric instruction (R1, R2), the metric is ignored. Defaults to default.metrics(), which returns a dataframe with instructios for default metrics, using the default summary types (con, inc, loc, glo, con.loc, con.glo, etc.).
#' @param custom.metrics A 2*x dataframe with an equivalent layout as default metrics, containing custom metric names and custom instructions. If a column name of 'custom.metrics' exists in 'default.metrics', it replaces the column, otherwise it is appended. A sorting algorithmus ensures that instructions are appended such that when a metric is used as minuend or subtrahend, this metric exists by the time it is required. Defaults to NULL.
#' @param preference.metrics A 2*x dataframe with an equivalent layout as default metrics, containing instructions for the calculation of preference-metrics. When the second and third row are NA, the metric as defined by the column name is identical to the value of the type/metric defined by the first row. Defaults to preference.metrics().
#' @param preference The identifiers in the measure-column used to index preference-summaries. No default.
#' @param notify Should progress information be provided. Defaults to TRUE.
#' @keywords summary
#' @export
#' @examples
#' summaries.perf = summarise.trials(     wdf = example.performance.data(), group.by = c('session','id','level','congruence'), make.trial_type = c('level','congruence'))
#' summaries.pref = summarise.trials.PREF(wdf = example.preference.data(),group.by0 = c('session','id','level','congruence'), make.trial_type = c('level','congruence'))
#' # Calculate trial type summaries from example.performance.data() with summarise.trials() and then calculate scores from these summaries
#' ldf = score.summaries(ldf = summaries.perf, identifier.cols = c('session','id','measure'))
#' # Calculate only OPS as difference between local and global trials
#' ldf = score.summaries(ldf = summaries.perf, identifier.cols = c('session','id','measure'), metrics = data.frame(OPS = c('loc','glo','diff')))
#' ldf = score.summaries(ldf = summaries, identifier.cols = c('session','id'), preference = c('mean_PREF','sum_PREF'))
#' debug(score.summaries)
score.summaries = function(ldf, identifier.cols, metrics = LoGloBias::default.metrics(), preference.metrics = LoGloBias::preference.metrics(), preference = NULL, measure.col = 'measure', trial_type.col = 'trial_type', notify = T){

  identifier.cols = unique(c(identifier.cols,measure.col))
  identifier.cols = identifier.cols[!identifier.cols %in% trial_type.col]
  if(measure.col != 'measure') stop("Currently, measure.col must be 'measure'")
  if(trial_type.col != 'trial_type') stop("Currently, trial_type.col must be 'trial_type'")
  if(any(!c('value','measure','trial_type') %in% colnames(ldf))) stop("'ldf' must contain cols named 'value', 'measure', and 'trial_type'")
  # TODO: Check if all groupings are equally-sized
  # TODO: Check if score.summaries requires equally-sized groupings
  # TODO: Implement free naming for measure col and trial_type col
  # TODO: Nicer notification of metrics, drop the splitting in diff and mins
  # TODO: Notification when a type or metric that is required does not exist (in the calculation loop); update info in the description

  ldf.type = ldf
  ind.type = lapply(ldf.type[,c(identifier.cols,'trial_type')], unique)

  # If present, separate the preference values from other values
  if(is.null(preference)) do.pref = F else if(any(!preference %in% ldf.type$measure)) stop("Not all names defined by 'preference' exist in the column [",measure.col,"]") else do.pref = T
  if(do.pref){
    if(notify) message("'",paste(preference,collapse = ','),"' found in column [measure]. Using separate calculation ('preference.metrics()') for the preference-based scores.")
    ldf.type.P = ldf.type[ ldf.type$measure %in% preference,]
    ldf.type  = ldf.type[!ldf.type$measure %in% preference,]
    ind.type.P = lapply(ldf.type.P[,c(identifier.cols,trial_type.col)], unique)
    ind.type  = lapply(ldf.type[ ,c(identifier.cols,trial_type.col)], unique)}

  # If the trial_types or metrics required for the calculation of a metric is neither present in ldf.type$trial_types nor in colnames(metrics), remove the metric from the list
  for (i in colnames(metrics)) if(any(!metrics[1:2,i] %in% ldf.type$trial_type)) if(any(!metrics[1:2,i] %in% colnames(metrics))) metrics[[i]] = NULL
  if(ncol(metrics)==0) {message("Metrics as instructed:"); print(metrics); stop("None of the trial trial_type names required were found in ldf. Please \n - either adhere to the naming convention 'loc' (local), 'glo' (global), 'con' (congruent), 'inc' (incongruent), 'ctr' (control), as well as 'loc.con' (local congruent), etc. \n - or redefine the names of the trial_types in by using 'custom.metrics'")}
  if(do.pref) {
    for (i in colnames(preference.metrics)) if(any(!preference.metrics[1:2,i] %in% c(ldf.type.P$trial_type,NA))) if(any(!preference.metrics[1:2,i] %in% colnames(preference.metrics))) preference.metrics[[i]] = NULL
    if(ncol(preference.metrics)==0) {message("Preference metrics as instructed:"); print(preference.metrics); stop("None of the trial trial_type names required were found in ldf. Please \n - either adhere to the naming convention 'loc' (local), 'glo' (global), 'con' (congruent), 'inc' (incongruent), 'ctr' (control), as well as 'loc.con' (local congruent), etc. \n - or redefine the names of the trial_types in by using 'custom.metrics'")}}

  # Notify of the calculations
  if(notify) {
    if(do.pref)                    {message("Preference calculation:");           print(preference.metrics)}
    if(any(metrics[3,] == 'diff')) {message("Metrics calculated as difference:"); print(metrics[,metrics[3,] == 'diff', drop = F], row.names = c('R1','R2','method'))}
    if(any(metrics[3,] == 'min'))  {message("Metrics calculated as min():");      print(metrics[,metrics[3,] == 'min',  drop = F], row.names = c('R1','R2','method'))}}

  ldf.metric = data.frame()
  # For each col in the standard metrics
  for (i in colnames(metrics)) {
    ab.val = list()
    # For first and second row of metrics[[i]], check if they are a trial trial_type or a metric, find and store the corresponding rows from ldf.type in a list
    for(j in 1:2) if(metrics[[i]][j] %in% unique(ldf.type$trial_type)) {ab.val[[j]] = ldf.type[ldf.type$trial_type %in% metrics[[i]][j],]} else if(metrics[[i]][j] %in% ldf.metric$metric) {ab.val[[j]] = ldf.metric[ldf.metric$metric %in% metrics[[i]][j],]}
    # Check the size of each part and left_join the two by group.by and measure
    if(nrow(ab.val[[1]]) != nrow(ab.val[[2]])) stop("Issue when calculating '",i,"': '",metrics[[i]][1],"' and '",metrics[[i]][2],"' have different rownumbers.")
    # ab.val = dplyr::left_join(ab.val[[1]],ab.val[[2]], by = identifier.cols)
    # if(metrics[[i]][3] == 'diff') ab.val$value = ab.val$value.x - ab.val$value.y else if(metrics[[i]][3] == 'ratio') ab.val$value = ab.val$value.x / ab.val$value.y else if(metrics[[i]][3] == 'ratio') ab.val$value = min(ab.val$value.x,ab.val$value.y) else stop("The method-row in the metric-instructions can only be 'diff', 'ratio', 'min', or NA")
    # for(j in 1:2) ab.val[[j]] = ab.val[[j]] %>% dplyr::arrange(!!dplyr::syms(identifier.cols))
    for (j in identifier.cols) if(any(ab.val[[1]][[j]] != ab.val[[2]][[j]], na.rm = T)) stop('Not properly sorted')
    # Calculate scores
    if(metrics[[i]][3] == 'diff') val = ab.val[[1]]$value - ab.val[[2]]$value else if(metrics[[i]][3] == 'min') val = apply(cbind(ab.val[[1]]$value, ab.val[[2]]$value), 1, min) else stop("Method '",metrics[[i]][3],"' is required to calculate '",colnames(metrics)[i],"', but is not implemented. Use 'diff' or 'min'")
    val0 = ab.val[[1]][,identifier.cols]
    # Add metric name, value, and rbind
    val0$metric = i
    val0$value = val
    ldf.metric = rbind(ldf.metric, val0)}

  ldf.metric.P = data.frame()
  # For each column in the preference metrics
  if(do.pref) for(i in colnames(preference.metrics)){
    ab.val = list()
    # For first and second row of preference.metrics[[i]], check if they are a trial trial_type or a metric, find and store the corresponding rows from ldf.type in a list
    for(j in 1:2) if(is.na(preference.metrics[[i]][j])) ab.val[[j]] = NA else if(preference.metrics[[i]][j] %in% ldf.type.P$trial_type) ab.val[[j]] = ldf.type.P[ldf.type.P$trial_type %in% preference.metrics[[i]][j],] else if(preference.metrics[[i]][j] %in% ldf.metric.P$metric) ab.val[[j]] = ldf.metric.P[ldf.metric.P$metric %in% metrics[[i]][j],]
    # Check the size of each part and left_join the two by group.by and measure
    if(!is.na(ab.val[1]) & !is.na(ab.val[2])) if(nrow(ab.val[[1]]) != nrow(ab.val[[2]])) stop("Issue when calculating '",i,"': '",preference.metrics[[i]][1],"' and '",preference.metrics[[i]][2],"' have different rownumbers.")
    # ab.val = dplyr::left_join(ab.val[[1]],ab.val[[2]], by = identifier.cols)
    # if(preference.metrics[[i]][3] == 'diff') ab.val$value = ab.val$value.x - ab.val$value.y else if(preference.metrics[[i]][3] == 'ratio') ab.val$value = ab.val$value.x / ab.val$value.y else if(preference.metrics[[i]][3] == 'ratio') ab.val$value = min(ab.val$value.x,ab.val$value.y) else stop("The method-row in the metric-instructions can only be 'diff', 'ratio', 'min', or NA")
    # for(j in 1:2) ab.val[[j]] = ab.val[[j]] %>% dplyr::arrange(!!dplyr::syms(identifier.cols))
    if(!is.na(ab.val[1]) & !is.na(ab.val[2])) for (j in identifier.cols) if(any(ab.val[[1]][[j]] != ab.val[[2]][[j]], na.rm = T)) stop('Not properly sorted')
    # Calculate scores
    if(is.na(preference.metrics[[i]][3])) val = ab.val[[1]]$value else if(preference.metrics[[i]][3] == 'diff') val = ab.val[[1]]$value - ab.val[[2]]$value else if(preference.metrics[[i]][3] == 'ratio') val = ab.val[[1]]$value / ab.val[[2]]$value else if(preference.metrics[[i]][3] == 'min') val = apply(cbind(ab.val[[1]]$value, ab.val[[2]]$value), 1, min) else stop("Method '",preference.metrics[[i]][3],"' is required to calculate '",colnames(preference.metrics)[i],"', but is not implemented. Use 'diff' or 'min'")
    val0 = ab.val[[1]][,identifier.cols]
    # Add metric name, value, and rbind
    val0$metric = i
    val0$value = val
    ldf.metric.P = rbind(ldf.metric.P, val0)}

  # ab.val = list()
  # For R1 and R2, check if they are a trial trial_type or a metric, find and store the corresponding rows from ldf.type in a list
  # for(j in 1:2) if(is.na(preference.metrics[[i]][j])) ab.val[[j]] = NA else if(preference.metrics[[i]][j] %in% ind.type.P$trial_type) {ab.val[[j]] = ldf.type.P[ldf.type.P$trial_type %in% preference.metrics[[i]][j],]} else if(preference.metrics[[i]][j] %in% unique(ldf.metric.P$metric)) {ab.val[[j]] = ldf.metric.P[ldf.metric.P$metric %in% metrics[[i]][j],]}
  # Check if the order of the rows (except value, metric, trial_type) is the same in R1 and R2
  # if(!is.na(ab.val[1]) & !is.na(ab.val[2])) if(sum(!ab.val[[1]][,!colnames(ab.val[[1]]) %in% c('value', 'metric', 'trial_type')] == ab.val[[2]][,!colnames(ab.val[[2]]) %in% c('value', 'metric', 'trial_type')])>0) stop("The order of rows does not match in the calculation of ",i,". This error should not happen and possibly requires comprehensive troubleshooting of 'score.summaries()'")
  # For the id.dataframe extract the identifier-columns from the minuend ldfs, remove the trial_type-col (if it exists) and replace/add the target metric
  # for(j in 1:2) if(!is.na(ab.val[j])) id.df = ab.val[[j]][,!colnames(ab.val[[j]]) %in% c('value','trial_type')]
  # id.df$metric = i
  # If the metric i is not specified in metrics[[i]][3], calculate the difference between [[1]] and [[2]], otherwise take the min
  # if(is.na(preference.metrics[[i]][3])) val = ab.val[[1]]$value else if(preference.metrics[[i]][3] == 'diff') val = ab.val[[1]]$value - ab.val[[2]]$value else if(preference.metrics[[i]][3] == 'min') val = apply(cbind(ab.val[[1]]$value, ab.val[[2]]$value), 1, min) else stop("Method '",preference.metrics[[i]][3],"' is required to calculate '",colnames(preference.metrics)[i],"', but is not implemented. Use 'diff' or 'min'")
  # cbind the resulting var-vector and the id.dataframe and rbind the it with the ldf containing the previous metrics
  # ldf.metric.P = rbind(ldf.metric.P, cbind(id.df, value = val))

  # Join the two score dataframes
  ldf.metric = rbind(ldf.metric, ldf.metric.P)

  # Arrange the order of columns and then order the rows by column from left to right
  ldf.metric = ldf.metric[,c(identifier.cols,'metric','value')]
  for (i in rev(c(identifier.cols,'metric'))) ldf.metric = ldf.metric[order(ldf.metric[[i]]),]
  rownames(ldf.metric) = NULL

  return(ldf.metric)
}





#' A function to correlate observations
#'
#' A function to correlated observations in a long format dataframe, separately for chosen groupings. Returns the results of the correlation, as specified by the cor-column.
#' @param ldf Long format dataframe with one column named 'value' containing the values, one identifier-column specifying type of the value (such as a column defining the metric), and at least one identifier-column that can be used for grouping (such as participant id).
#' @param correlate.by Name of the column containing the identifiers that should be correlated with each other. Defaults to 'metric'.
#' @param group.by Name of the identifier-columns that are used to to group the observations. Each grouping is correlated internally by 'correlate.by'. E.g. group.by = c('sessions', 'measures') together with correlate.by = 'metric' means that metrics will be correlated with each other, for each session and each measure separately. Is mutually exclusive with collapse. Defaults to NULL.
#' @param collapse Name of the identifier-columns that are NOT used to to group the observations. E.g. collapse = c('sessions','participant id') together with correlate.by = 'metric' means that the metrics will be correlated for each session separately, but rather be pooled and 'session' vanishes as independent grouping in the results. Is mutually exclusive with group.by. Defaults to NULL.
#' @param method Method to be used by cor.test(). Choices are 'pearson', 'spearman', and 'kendall'. Defaults to 'pearson'.
#' @param notify Provides progress information. Defaults to TRUE.
#' @return s statistic, e.g. t-statistic for pearson
#' @return n number, degrees of freedom for pearson
#' @return p significance, p-value
#' @return c correlation, e.g. r for pearson
#' @return CI1,CI2 95% confidence interval
#' @keywords summary
#' @export
#' @examples
#' # Summarise trials to trial types, then calculate scores
#' scores = score.summaries(ldf = summarise.trials(ldf = example.performance.data()))
#' # Correlate metrics in the score-ldf by collapsing the id-column, ie. for all other combinations of columns (except metric and value) the correlations will be calculated separately
#' correlate.values(ldf = scores, correlate.by = 'metric', collapse = 'id')
#' # With the given data in scores, this is equivalent to grouping by session and measure
#' correlate.values(ldf = scores, correlate.by = 'metric', group.by = c('session', 'measure' ))
correlate.values = function(ldf, correlate.by = 'metric', group.by = NULL, collapse = NULL, method = 'pearson', notify = T){

  if(!'value' %in% colnames(ldf)) stop("'ldf' must be a long format dataframe with the column 'value' holding the values and all other columns being used to index the values")
  if(is.null(group.by) == is.null(collapse)) stop("EITHER 'group.by' OR 'collapse' can be used")
  if(any(!group.by %in% colnames(ldf))) stop(paste(group.by[!group.by %in% colnames(ldf)], collapse = ',')," is required by 'group.by' but does not exist in the colnames of 'ldf'")
  if(any(!correlate.by %in% colnames(ldf))) stop(paste(correlate.by[!correlate.by %in% colnames(ldf)], collapse = ',')," is required by 'correlate.by' but does not exist in the colnames of 'ldf'")
  if(any(!collapse %in% colnames(ldf))) stop(paste(collapse[!collapse %in% colnames(ldf)], collapse = ',')," is required by 'collapse' but does not exist in the colnames of 'ldf'")
  if(length(correlate.by)>1) stop("'correlate.by' can only specify one column")

  # If group.by was provided, the grouping cols group.by. else if collapse was provided, the grouping cols are all cols except correlate.by, collapse, and value, else the grouping cols are all cols except correlate.by, and value.
  if(!is.null(group.by)) group.by = group.by else if(!is.null(collapse)) group.by = colnames(ldf)[!colnames(ldf) %in% c(correlate.by, collapse, 'value')] else group.by = colnames(ldf)[!colnames(ldf) %in% c(correlate.by, 'value')]

  # Pivot wider by putting the values for each identifier in correlate.by into its own column
  x = ldf %>% tidyr::pivot_wider(names_from = dplyr::all_of(correlate.by), values_from = 'value')
  z = data.frame()
  # For each combination of the unique values in col 'correlate.by'
  fr = as.matrix(expand.grid(unique(ldf[,correlate.by]),unique(ldf[,correlate.by])))
  for (i in 1:nrow(fr)) {
    print(paste("Correlating",fr[i,1],"with",fr[i,2],"  ",round(i/nrow(fr),2)))
    suppressMessages({
      y = as.data.frame(x) %>%
        # Group the data as defined by group.by
        dplyr::group_by(dplyr::across(dplyr::all_of(group.by))) %>%
        # Calculate the correlation with cor.test and save the htest output as list element in the tibble
        dplyr::summarise(cortest=list(cor.test(.data[[fr[i,1]]], .data[[fr[i,2]]], method = method, na.rm = T))) %>%
        # Mutate each listelement by extracting the statistic s, the number of participants n, the p-value p, the correlation c, and the lower and upper confidence interval and storing each in its own colum
        mutate(
          corr = purrr::map(cortest, ~.[1:4]),
          s = purrr::map_dbl(cortest, ~.[[1]]),
          n = ifelse(method == 'pearson', purrr::map_dbl(cortest, ~.[[2]]), NA),
          p = purrr::map_dbl(cortest, ~.[[3]]),
          c = purrr::map_dbl(cortest, ~.[[4]]),
          CI1 = ifelse(method == 'pearson', purrr::map_dbl(cortest, ~.[[9]][1]), NA),
          CI2 = ifelse(method == 'pearson', purrr::map_dbl(cortest, ~.[[9]][2]), NA)) %>%
        # Remove unnecessary columns
        dplyr::select(-corr, -cortest)
    })
    # Add cols to store which elements of 'correlate.by' were correlated
    y[,paste0(correlate.by,'.1')] = fr[i,1]
    y[,paste0(correlate.by,'.2')] = fr[i,2]
    # Add to the full dataframe
    z = rbind(z,y)}
  # Turn the semi-ldf into a full ldf by putting all correlation statistics and values into a single value column and create a 'cor'-identifier col
  return(z %>% tidyr::pivot_longer(cols = c('s','n','p','c','CI1','CI2'), names_to = 'cor', values_to = 'value'))
}



#' A function to group observations and calculate statistics
#'
#' A function to group observations in a long format dataframe and calulate a range of statistics.
#' @param ldf Long format dataframe with one column named 'value' containing the values, one identifier-column specifying type of the value (such as a column defining the metric), and at least one identifier-column that can be used for grouping (such as participant id).
#' @param group.by Name of the identifier-columns that are used to to group the observations. Statistics are calculate for each grouping separately, e.g. group.by = c('sessions', 'measures') means that the statistic will be calculated separately for each session and each measure. Is mutually exclusive with collapse. Defaults to NULL.
#' @param collapse Name of the identifier-columns that are NOT used to to group the observations. E.g. collapse = c('sessions','participant id') together with correlate.by = 'metric' means that the metrics will be correlated for each session separately, but rather be pooled and 'session' vanishes as independent grouping in the results. Is mutually exclusive with group.by. Defaults to NULL.
#' @param statistics List of statistics to be applied to the groupings. The name of a list element is the statistic-name and the element defines the name of the function used to calculate it. Defaults to 'list(mean = 'mean', med = 'median', SD = 'sd', IQR = 'iqr', MAD = 'mad', skewness = 'skewness')'.
#' @keywords summary, statistic
#' @export
#' @examples
#' # Summarise trials to trial types, then calculate scores
#' scores = score.summaries(ldf = summarise.trials(ldf = example.performance.data()))
#' # Calculate statistics in the score-ldf by collapsing the id-column, i.e. for all other combinations of columns (except value) the statistic will be calculated separately
#' calculate.statistics(ldf = scores, collapse = 'id')
#' # With the given data in scores, this is equivalent to grouping by session and measure
#' calculate.statistics(ldf = scores, group.by = c('session', 'measure' ))
calculate.statistics = function(ldf, group.by = NULL, collapse = NULL, statistics = list(mean = 'mean', med = 'median', SD = 'sd', IQR = 'IQR', MAD = 'mad', skewness = 'skewness')){

  if(!'value' %in% colnames(ldf)) stop("'ldf' must be a long format dataframe with the column 'value' holding the values and all other columns being used to index the values")
  if(is.null(collapse) == is.null(group.by)) stop("EITHER 'collapse' OR 'group.by' can be used")
  if(any(!collapse %in% colnames(ldf))) stop(paste(collapse[!collapse %in% colnames(ldf)], collapse = ',')," is required by 'collapse' but does not exist in the colnames of 'ldf'")
  if(any(!group.by %in% colnames(ldf))) stop(paste(group.by[!group.by %in% colnames(ldf)], collapse = ',')," is required by 'group.by' but does not exist in the colnames of 'ldf'")

  # If collapse was provided, the grouping cols are all cols except collapse and value, else group.by are the grouping cols
  if(!is.null(collapse)) group.by = colnames(ldf)[!colnames(ldf) %in% c(collapse, 'value')] else if(!is.null(group.by)) group.by = group.by else group.by = colnames(ldf)[!colnames(ldf) %in% 'value']

  x = data.frame()
  for(i in 1:length(statistics)){
    # For each statistic, group the data by the group.by, add a col denoting the apply the statistic, and rbind with x
    y = ldf %>% dplyr::group_by(dplyr::across(dplyr::all_of(group.by))) %>% dplyr::summarise(value = do.call(statistics[[i]], list(value, na.rm = T)))
    y$statistic = names(statistics)[i]
    x = rbind(x, as.data.frame(y))}

  return(x)
}
